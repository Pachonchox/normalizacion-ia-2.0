# ğŸš€ Sistema de Scrapers Intercalados

Sistema independiente de scrapers para retailers chilenos con orquestaciÃ³n automÃ¡tica.

## ğŸ“ Estructura

```
Scrappers/
â”œâ”€â”€ ripley_ultra_stealth_v3.py     # Scraper Ripley (ultra stealth)
â”œâ”€â”€ falabella_busqueda_continuo.py # Scraper Falabella  
â”œâ”€â”€ paris_busqueda_continuo.py     # Scraper Paris
â”œâ”€â”€ scraper_orchestrator.py        # Orquestador principal
â”œâ”€â”€ requirements.txt               # Dependencias
â””â”€â”€ README.md                      # Este archivo

data/
â”œâ”€â”€ ripley/                        # Datos scrapeados de Ripley
â”œâ”€â”€ falabella/                     # Datos scrapeados de Falabella  
â”œâ”€â”€ paris/                         # Datos scrapeados de Paris
â””â”€â”€ logs/                          # Logs del orquestador
```

## âš™ï¸ ConfiguraciÃ³n

**Todos los scrapers configurados a 10 pÃ¡ginas exactas:**
- âœ… Ripley: 10 pÃ¡ginas fijas
- âœ… Falabella: 10 pÃ¡ginas fijas  
- âœ… Paris: 10 pÃ¡ginas fijas

**Almacenamiento independiente:**
- Cada retailer guarda en su carpeta `/data/{retailer}/`
- Logs centralizados en `/data/logs/`

## ğŸš€ InstalaciÃ³n

```bash
# Desde carpeta Scrappers
cd Scrappers
pip install -r requirements.txt
```

## ğŸ“‹ Uso

### Ejecutar un solo ciclo (todos los scrapers una vez)
```bash
python scraper_orchestrator.py
```

### Ejecutar modo continuo
```bash
# Continuo infinito
python scraper_orchestrator.py --mode continuous

# Continuo con lÃ­mite de ciclos
python scraper_orchestrator.py --mode continuous --max-cycles 5
```

### Ejecutar scraper especÃ­fico
```bash
# Solo Ripley
python scraper_orchestrator.py --scraper ripley

# Solo Falabella
python scraper_orchestrator.py --scraper falabella

# Solo Paris
python scraper_orchestrator.py --scraper paris
```

### Ver estado
```bash
python scraper_orchestrator.py --mode status
```

### EjecuciÃ³n directa de scrapers
```bash
# Ejecutar scrapers individualmente
python ripley_ultra_stealth_v3.py
python falabella_busqueda_continuo.py  
python paris_busqueda_continuo.py
```

## ğŸ”„ Funcionamiento Intercalado

El orquestador ejecuta los scrapers de forma inteligente:

1. **Orden aleatorio** cada ciclo
2. **Pausas intercaladas** entre scrapers (5-15 min)
3. **Pausas entre ciclos** completos (30-60 min)
4. **EjecuciÃ³n independiente** de cada scraper
5. **Logs centralizados** para monitoreo

## ğŸ“Š Salida de Datos

Cada scraper genera archivos JSON en su carpeta correspondiente:

```json
{
  "metadata": {
    "scraped_at": "2025-09-09 06:45:00",
    "search_term": "celulares",
    "total_products": 240,
    "pages_scraped": 10,
    "retailer": "ripley"
  },
  "products": [...]
}
```

## ğŸ›¡ï¸ CaracterÃ­sticas de Seguridad

- **Ultra-stealth** para Ripley (bypass Cloudflare)
- **RotaciÃ³n de User Agents** 
- **Delays humanos** aleatorios
- **Manejo de errores** robusto
- **Reintentos automÃ¡ticos**

## ğŸ“ˆ Monitoreo

```bash
# Ver logs en tiempo real
tail -f ../data/logs/orchestrator.log

# Verificar archivos generados
ls -la ../data/*/
```

## âš ï¸ Consideraciones

- **Independiente** del sistema de normalizaciÃ³n
- **Sin configuraciÃ³n centralizada** (como solicitado)
- **10 pÃ¡ginas fijas** por scraper
- **EjecuciÃ³n intercalada** para evitar bloqueos
- **Almacenamiento separado** por retailer