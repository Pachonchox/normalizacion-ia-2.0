1) Veredicto r√°pido

Cobertura actual (muy buena, ~80%)

Routing por complejidad con distribuci√≥n por modelo y batching (incluye ejemplos de prompts ‚Äúminimal‚Äù, ‚Äústandard‚Äù y ‚Äúdetailed‚Äù). ‚úîÔ∏è

OpenAI Batch API con JSONL, custom_id para idempotency mapping y recuperaci√≥n asincr√≥nica (incluye estructura exacta de archivo de requests y resultados). ‚úîÔ∏è

Cache sem√°ntico con embeddings y pgvector/HNSW (persistencia y b√∫squeda por similitud). ‚úîÔ∏è

An√°lisis de costos/ROI y m√©tricas de performance (throughput/latencia/precisi√≥n). ‚úîÔ∏è

Checklist de producci√≥n razonable (config de pgvector, √≠ndices, monitoreo, pruebas previas, rollback). ‚úîÔ∏è

Brechas y desalineaciones (cr√≠ticas a corregir)

Modelos y fallback: el documento usa ‚ÄúGPT‚Äë5‚Äëmini / GPT‚Äë5‚Äù y hasta un fallback a GPT‚Äë4o‚Äëmini (!). En tus requisitos pediste gpt‚Äë4o‚Äëmini como primario y gpt‚Äë4o como fallback (o en su variante previa, GPT‚Äë5‚Äëmini‚ÜíGPT‚Äë5). Debe parametrizarse para evitar mezclar familias/modelos y asegurar fallback a un modelo m√°s potente, no a uno menor. ‚ö†Ô∏è

Validaci√≥n estricta (taxonom√≠a/esquema): no aparece un bloque expl√≠cito que valide la categor√≠a devuelta por IA contra la taxonom√≠a ni una validaci√≥n por esquema de atributos por categor√≠a antes de insertar en BD. Esto fue un pilar de la propuesta (calidad/consistencia). ‚ö†Ô∏è

Cache L1 (hot) y pol√≠tica de TTL: el doc cubre cache sem√°ntico y persistencia con pgvector, pero no especifica un L1 in‚Äëmemory/Redis (para hits sub‚Äë200ms) ni TTLs adaptativos por volatilidad (precios/cambios frecuentes). ‚ö†Ô∏è

Gating de calidad: hay confidence en la salida, pero falta la pol√≠tica de aceptaci√≥n (umbrales por categor√≠a/campo) y la re‚Äëinvocaci√≥n/fallback autom√°tica condicionada a esos umbrales (calidad de JSON, cobertura de atributos clave, etc.). ‚ö†Ô∏è

Rate limiting proactivo / backpressure: el doc define monitoring y estados del batch, pero no deja claro el throttling proactivo (por ejemplo, token bucket por modelo) ni circuit‚Äëbreakers para contener errores 429/5xx o picos. ‚ö†Ô∏è

Inserci√≥n en BD y contratos de datos: faltan pasos formales (y campos) de mapeo final a productos_maestros/ai_metadata_cache con idempotency keys y validaciones previas a INSERT (e.g., marca conocida/alias, atributos esperados por categor√≠a, normalized_name consistente). ‚ö†Ô∏è

Conclusi√≥n: Tu documento ya resuelve routing + batch + cache sem√°ntico + costos. Para llegar al 100% del plan, necesitas: (a) parametrizar modelos y corregir fallback, (b) insertar una fase formal de validaci√≥n (taxonom√≠a/esquema) y (c) completar operativa/fiabilidad (L1 cache, throttling, idempotencia e inserci√≥n BD).

2) Matriz de alineaci√≥n (lo que cubre vs. lo faltante)
Requisito del plan	Estado en tu doc	Observaci√≥n
Routing por complejidad	Cubre	Distribuci√≥n 80/15/5 y prompts por modo. Ajustar modelos/fallback.
OpenAI Batch API	Cubre	JSONL requests/responses + custom_id ‚úîÔ∏è.
Cache sem√°ntico	Cubre	pgvector/HNSW; falta L1‚ÄëRedis y TTLs.
Validaci√≥n taxonom√≠a/esquema	Falta	A√±adir bloque de validator y reglas por categor√≠a.
Fallback inteligente	Parcial	Fallback apunta a modelo menor en un tramo. Debe ir a modelo mayor.
Gating de calidad	Parcial	Usa confidence, falta umbrales, retry y escalado formal.
Inserci√≥n en BD	Parcial	Falta pipeline de inserci√≥n con idempotencia y contratos.
Throttling/Backpressure	Falta	A√±adir rate limits por modelo y circuit breakers.
Observabilidad de costos	Cubre	M√©tricas y dashboard de batch.
3) Plan de cambio para cubrir el 100%
A. Modelos y fallback (parametrizaci√≥n y correcci√≥n)

Qu√© cambiar: Centralizar en config.llm.toml los modelos primary_model y fallback_model.

Opci√≥n A (tu doc actual): gpt‚Äë5‚Äëmini ‚Üí gpt‚Äë5.

Opci√≥n B (tu requerimiento previo): gpt‚Äë4o‚Äëmini ‚Üí gpt‚Äë4o.

Regla: fallback siempre a un modelo m√°s potente (jam√°s a uno menor), condicionado por: JSON inv√°lido, confidence < umbral, o atributos cr√≠ticos ausentes.

D√≥nde reflejarlo: secci√≥n FASE DE ROUTING y Flujo de Fallback (intercambiar el ‚ÄúGPT‚Äë4o‚Äëmini legacy‚Äù por el full model y dejar rules como √∫ltimo recurso).

B. Validaci√≥n estricta (taxonom√≠a y esquema de atributos)

Insertar nueva fase entre ‚ÄúResultados‚Äù ‚Üí ‚ÄúProductos Normalizados‚Äù:

Taxonomy check: si category_suggestion existe, verificar contra taxonom√≠a (ID/nombre/sin√≥nimos). Si no es v√°lida, conservar categor√≠a base.

Attribute schema por categor√≠a: whitelist de claves + tipos/conversi√≥n (e.g., screen_size num√©rico, volume_ml entero). Descartar claves fuera de esquema.

Gating por confianza: confidence_global y coverage (porcentaje de atributos clave extra√≠dos) ‚â• umbrales (p.ej. 0.7 y 0.8). Si no, reintentar o fallback.

Brand alias mapping: normalizar marca contra cat√°logo/aliases.

Resultado: JSON validado listo para insertar (o marcado para retry/review).

C. Cache inteligente multinivel

A√±adir L1 (Redis): clave = fingerprint + schema_version; TTL adaptativo por categor√≠a/volatilidad (ej. TVs 1d, perfumes 30d).

Mantener L2 (pgvector): como en el doc; a√±adir umbral de similitud por categor√≠a (ej. smartphones ‚â•0.92; perfumes ‚â•0.90).

Pol√≠tica de adaptaci√≥n: si reuso sem√°ntico, permitir ajuste de diferencias evidentes (p.ej., capacity 128GB vs 256GB) antes de validaci√≥n.

Invalidaci√≥n: por nueva versi√≥n de prompts/modelo o cambios estructurales (a√±adir namespace en la clave).

D. Batch y asincron√≠a (end‚Äëto‚Äëend)

Batch builder: mantener JSONL como muestras (ok). A√±adir response_format: json_object (ya est√°) y seed/version en system para trazabilidad.

Submit/Status: mantener ciclo de vida y monitoring; a√±adir reconciliaci√≥n por custom_id ‚Üí upsert cache/BD.

Plan B: si el batch timeout/falla, caer a procesamiento individual con throttling (tu fallback chain ya lo sugiere; reordenar para usar modelo full antes que legacy mini).

E. Inserci√≥n en BD (idempotencia y contratos)

Idempotencia: usar custom_id y/o fingerprint como llave natural en ai_metadata_cache y productos_maestros (ON CONFLICT DO UPDATE).

Contratos: Validar antes de INSERT:

brand no vac√≠a (o ‚ÄúDESCONOCIDA‚Äù), category v√°lida, normalized_name no trivial.

attributes conforme a esquema.

price_current presente y positivo.

Trazabilidad: guardar model_used, tokens, cost_usd_est, prompt_version.

F. Throttling, backpressure y retries

Rate Limits: por modelo y canal (batch vs individual) usando token bucket.

Circuit breaker: cortar env√≠os si tasa de error por encima de umbral.

Retry policy: exponencial con jitter y m√°ximo por item.

G. Observabilidad y costos

M√©tricas: %cache_hit_l1, %cache_hit_l2, %llm_calls, %fallback_full, avg_confidence, cost_per_product, tokens_in/out.

Alertas: cost budget diario y % de fallback_full (si supera X%).

A/B de prompts: tu doc ya separa minimal vs detailed; a√±ade banderas para experimentar por categor√≠a.

4) Cambios concretos al documento (qu√© actualizar en tu MD)

Arquitectura (Mermaid)

A√±adir L1 Redis antes de ‚ÄúSemantic Cache / pgvector‚Äù.

Insertar un bloque ‚ÄúTaxonomy & Schema Validator‚Äù entre ‚ÄúResultados‚Äù y ‚ÄúProductos Normalizados‚Äù.

Modelos

Parametrizar: ‚ÄúPrimary = gpt‚ÄëX‚Äëmini, Fallback = gpt‚ÄëX (mismo family id)‚Äù.

Corregir flujo de fallback para que nunca degrade a un modelo menor.

FASE DE BATCH

Mantener JSONL y custom_id.

A√±adir nota: ‚Äúcustom_id se usa como idempotency key en BD/cache‚Äù.

FASE DE RECUPERACI√ìN Y CACHE

Indicar L1 Redis ‚Üí L2 pgvector (con umbrales por categor√≠a) y TTL.

A√±adir ‚ÄúAdaptaci√≥n de diferencias‚Äù cuando se reutiliza un vecino sem√°ntico.

Validaci√≥n (nuevo cap√≠tulo)

Reglas de taxonom√≠a/atributos (listas por categor√≠a).

Umbrales de aceptaci√≥n (confidence, coverage).

Inserci√≥n BD

Paso‚Äëa‚Äëpaso: validado ‚Üí upsert ai_cache ‚Üí upsert productos_maestros ‚Üí upsert precios.

Campos de auditor√≠a: model_used, prompt_version, ai_confidence.

Checklist

Agregar: Redis, rate limits, circuit breakers, versionado de prompts.

5) ¬øCubre lo esencial de mi propuesta?

S√≠, en gran medida. Tu BATCH_PROCESSING_FLOW.md ya resuelve las piezas m√°s costosas y diferenciales: routing, batch API, cache sem√°ntico y medici√≥n de costos/throughput. Con los ajustes anteriores (modelos/fallback, validaci√≥n estricta, L1 cache, throttling y contratos de BD) quedar√° totalmente alineado con el plan de Normalizaci√≥n IA 2.0 y listo para producci√≥n robusta.

6) Pr√≥ximos pasos (pr√°cticos)

Actualizar el doc con los cambios de secciones A‚ÄìG (arriba) y el diagrama.

Parametrizar modelos en config y corregir fallback.

Implementar L1 Redis + TTL + hit counters.

A√±adir ‚ÄúTaxonomy & Schema Validator‚Äù en el flujo post‚Äëbatch.

Definir umbrales (confidence, coverage) por categor√≠a.

Conectar inserci√≥n BD con idempotencia (custom_id/fingerprint).

Prueba controlada con 1.000 productos (medir %cache_hit, %fallback_full, costo/producto).

Si quieres, te preparo el addendum del documento con los bloques exactos de Validaci√≥n, Inserci√≥n BD y el diagrama actualizado para que tu equipo lo incorpore tal cual.

T√∫ dijiste:
actualiza el documento completo, sugiere los promp exactos, y los flujos, para que cumpla 100% el plan, debe ser detallado. y con todas las recomendaciones. necesito que sea profesional para que un equipo pueda seguir las indicaciones 
ChatGPT Plus
Solicitud de GPT-5 pro
Reasoned for 5m 23s

Below is the updated BATCH_PROCESSING_FLOW.md (v2) you can drop into your repo to fully cover the 100% IA plan, with exact prompts, end‚Äëto‚Äëend flows, validation, cache strategy, routing/fallback, batch, DB insertion and operational runbooks. It supersedes the prior document and keeps what already works (Batch API, custom_id, pgvector) while fixing gaps (taxonomy/attribute validation, L1 cache, strict gating, throttling, DB contracts). Where I reference your previous doc (v1), I cite it inline.

üì¶ FLUJO DE PROCESAMIENTO BATCH (IA) ‚Äî Normalizaci√≥n E2E v2

Objetivo: Normalizaci√≥n 100% IA con cache inteligente multinivel, routing de modelos con fallback, Batch API, validaci√≥n estricta (taxonom√≠a + esquema de atributos) y persistencia idempotente.
Compatibilidad: mantiene Batch JSONL + custom_id e indexaci√≥n vectorial (pgvector) ya definidas en v1.

üß≠ Resumen Ejecutivo (qu√© cambia vs v1)

Model Routing parametrizable (default primary = gpt‚Äë4o‚Äëmini, fallback = gpt‚Äë4o) con gating de calidad (JSON v√°lido, confianza y cobertura de atributos).

Cache IA Multinivel: L1 Redis (hot, TTL din√°mico) ‚Üí L2 Sem√°ntico (pgvector/Milvus) ‚Üí L3 Postgres (persistente).

Validaci√≥n estricta pre‚ÄëBD: Taxonom√≠a (ID/sin√≥nimo v√°lido), Esquema de atributos por categor√≠a (tipado/whitelist), mapeo de marca por aliases, umbrales por categor√≠a.

Batch end‚Äëto‚Äëend: sigue OpenAI Batch API con JSONL + custom_id (idempotencia) y reconciliaci√≥n de respuestas.

Operabilidad: throttling proactivo, circuit breakers, m√©tricas de costo/latencia/confianza, rollback plan.

‚öôÔ∏è Configuraci√≥n (toml / env)
[llm]
enabled = true
primary_model = "gpt-4o-mini"   # alternativo soportado: "gpt-5-mini"
fallback_model = "gpt-4o"       # alternativo soportado: "gpt-5"
temperature = 0.1
max_tokens_primary = 400
max_tokens_fallback = 800
response_format = "json_object" # estricto
timeout_seconds = 30

[llm.gating]
min_confidence = 0.70           # global m√≠nimo aceptable
min_attr_coverage = 0.70        # % claves esperadas presentes

[llm.routing_weights]
simple = 0.80
complex = 0.20

[cache]
version_namespace = "norm-ia-v2"
l1_redis_ttl_seconds_default = 3600
l1_redis_ttl_seconds_by_category.smartphones = 86400
l1_redis_ttl_seconds_by_category.perfumes    = 2592000
l1_redis_ttl_seconds_by_category.smart_tv    = 604800
l1_redis_ttl_seconds_by_category.notebooks   = 604800

[vector]
# usar uno de ambos backends
backend = "pgvector"            # "milvus" alternativo
similarity_threshold.global = 0.90
similarity_threshold.smartphones = 0.92
similarity_threshold.perfumes = 0.90
similarity_threshold.smart_tv = 0.88
similarity_threshold.notebooks = 0.92
top_k = 3

[rate_limits]
rpm_primary = 500
rpm_fallback = 100
batch_size_optimal = 10000      # por archivo JSONL

[validation]
taxonomy_policy = "strict"      # strict|lenient|disabled
reject_if_price_missing = true


Nota: v1 ya estandariza JSONL + custom_id y Batch API; se mantiene y refuerza con idempotencia/reconciliaci√≥n.

üèóÔ∏è Arquitectura (Mermaid)
flowchart TD
  A[Productos RAW] --> F[Pre‚ÄëFiltro negocio (opc)]
  F --> B[Routing Complejidad]
  subgraph Model Router
    B -->|simple| M1[primary_model (gpt-4o-mini)]
    B -->|complejo| M2[fallback_candidate (gpt-4o)]
  end

  A --> C{Cache IA L1?}
  C -->|hit| R1[Respuesta cache L1]
  C -->|miss| D{Cache IA L2 sem√°ntico?}
  D -->|hit sim>=Œ∏| R2[Reutilizaci√≥n + Adaptaci√≥n]
  D -->|miss| E[Batch Builder JSONL]
  E --> H[OpenAI Batch API]
  H --> I[Resultados JSONL]

  R1 --> V[Validador Taxonom√≠a/Atributos]
  R2 --> V
  I --> V
  V -->|ok| J[Persistencia BD]
  V -->|fail| K{Fallback/Retry?}
  K -->|yes| M2
  M2 --> V

  subgraph Cache Persistente
    V --> L3[(PostgreSQL ai_metadata_cache)]
    V --> L1[(Redis HOT)]
    V --> L2[(Vector DB: pgvector/Milvus)]
  end

  J --> O[productos_maestros + precios]

üîÅ Flujo E2E (paso a paso)

Ingesta & Pre‚ÄëFiltro (opcional)

Descarta reacondicionados/accesorios si tu negocio lo requiere.

Categor√≠a inicial (from taxonom√≠a)

Determina category_id tentativa para guiar prompts (se corregir√° si IA sugiere otra v√°lida).

Cache L1 (Redis)

Clave: {namespace}:{fingerprint}; TTL por categor√≠a/volatilidad. Hit ‚áí saltar a validaci√≥n.

Cache L2 Sem√°ntico (pgvector/Milvus)

Embedding de name_raw; busca vecinos top_k, si cosine_sim ‚â• Œ∏_cat, reutiliza metadata y adapta diferencias obvias (p. ej., capacity 128‚Üí256 si difiere solo eso).

Batch Builder JSONL (si hay N‚â•100‚Äì1k productos)

Agrupa por modelo (primary_model vs candidatos complejos) y categor√≠a.

Genera JSONL (uno por modelo) con custom_id = {batch_id}_{i}_{sku|source_id}.

Submit Batch API

Sube archivos, crea job (ventana 24h), guarda batch_id, coste -50% (v1).

Polling & Download

Estados: validating ‚Üí in_progress ‚Üí completed; descarga *_results.jsonl. (v1)

Parsing & Reconciliaci√≥n

Reconcilia por custom_id; reintenta individuales fallidos con throttling.

Validaci√≥n estricta (nuevo, ver abajo)

Taxonom√≠a, atributos por categor√≠a, marca (aliases), gating (confianza/cobertura).

Persistencia & Cache

Upsert en ai_metadata_cache + L1 + L2; upsert productos_maestros y precios_actuales.

M√©tricas/Alertas

%cache_hits L1/L2, %fallback_full, cost_per_product, avg_confidence, tokens_in/out, latencias, errores por causa. (v1 ya agrega costos/throughput; aqu√≠ ampliamos)

üß™ Contratos de Datos
1) Request (por √≠tem) ‚Üí LLM
{
  "retailer": "Falabella",
  "source_id": "SKU123",
  "name_raw": "iPhone 15 Pro Max 256GB Negro Liberado",
  "category_hint": "smartphones",
  "price_clp": 1299990
}

2) Respuesta IA (obligatorio JSON estricto)
{
  "brand": "APPLE",
  "model": "iPhone 15 Pro Max",
  "normalized_name": "APPLE iPhone 15 Pro Max 256GB Negro",
  "attributes": {
    "capacity": "256GB",
    "color": "negro",
    "screen_size": "6.7",
    "network": "5G"
  },
  "confidence": 0.93,
  "category_suggestion": "smartphones"
}


Claves m√≠nimas requeridas (antes de BD): brand, model, normalized_name, attributes (objeto), confidence.
Observaci√≥n: v1 ya enfatizaba JSON only en Batch; mantenemos response_format = json_object.

üß© Validaci√≥n estricta (previa a BD)

Taxonom√≠a:

Si category_suggestion ‚â† category_hint, aceptar solo si existe en taxonom√≠a (ID/nombre/sin√≥nimo). Si no, conservar category_hint (o marcar para revisi√≥n).

Esquema de atributos por categor√≠a:

Whitelist y tipado por categor√≠a:

smartphones: capacity(str), color(str), screen_size(num), network(enum: 4G/5G).

notebooks: screen_size(num), ram(str), storage(str/enum).

smart_tv: screen_size(num), panel(enum: OLED/QLED/4K/8K/FHD/HD).

perfumes: volume_ml(int), concentration(enum: EDP/EDT/Parfum), gender(enum: Mujer/Hombre/Unisex).

Normalizar tipos (e.g., "6.7" ‚Üí 6.7), descartar claves no v√°lidas para la categor√≠a.

Marca (aliases):

Mapear a BRAND can√≥nica; si desconocida, DESCONOCIDA y log de alerta.

Gating de calidad:

confidence ‚â• min_confidence y attr_coverage ‚â• min_attr_coverage.

Si falla: fallback al modelo superior o retry.

Precio:

Rechazar si price_current ausente/‚â§0 (configurable).

Nombre normalizado:

No vac√≠o, no gen√©rico; preferir ‚ÄúBRAND MODEL + atributo clave‚Äù.

Saneamiento:

Prohibidas palabras de descarte (‚Äúreacondicionado‚Äù) tras pre‚Äëfiltro; limpiar HTML/emoji si aplicara.

üß† Routing de modelos + Fallback

Heur√≠stica de complejidad (score 0‚Äì1): longitud del nombre, tecnicismos detectados, categor√≠a, rareza de marca, presencia de m√∫ltiples specs.

score < 0.3 ‚áí primary_model (p.ej., gpt‚Äë4o‚Äëmini).

0.3 ‚â§ score < 0.7 ‚áí primary_model + gating.

score ‚â• 0.7 ‚áí fallback_model (p.ej., gpt‚Äë4o).

Fallback autom√°tico si:

Respuesta no es JSON v√°lido,

confidence < umbral,

Faltan atributos esenciales por categor√≠a,

Categor√≠a sugerida inv√°lida.

En v1 el ‚Äúfallback chain‚Äù mezclaba modelos; aqu√≠ aseguramos siempre subir a un modelo m√°s potente.

üßæ Prompts EXACTOS (System/User) ‚Äî por categor√≠a y modo

Reglas comunes

System (constante): ‚ÄúEres un experto en productos retail de Chile. Responde solo JSON v√°lido (RFC 8259), sin texto extra.‚Äù

response_format: json_object

temperature: 0.1 (0.05 en fallback)

Idioma de salida: valores normalizados (marca may√∫sculas, enums definidos).

A) Smartphones

STANDARD (primary_model)

[system]
Eres un experto en productos retail de Chile. Responde solo JSON v√°lido (RFC 8259), sin texto extra.

[user]
Normaliza el siguiente producto para comparaci√≥n inter-retail:

PRODUCTO: "{name_raw}"
CATEGOR√çA: "smartphones"
PRECIO_CLP: {price_clp}
RETAILER: "{retailer}"

Estructura EXACTA:
{
  "brand": "MARCA EN MAY√öSCULAS (ej: APPLE, SAMSUNG, XIAOMI)",
  "model": "modelo espec√≠fico sin la marca",
  "normalized_name": "nombre limpio y consistente",
  "attributes": {
    "capacity": "ej: 128GB, 256GB, 1TB",
    "color": "ej: negro, blanco, azul",
    "screen_size": "ej: 6.7",
    "network": "4G o 5G"
  },
  "confidence": 0.0,
  "category_suggestion": "smartphones o vac√≠o si coincide"
}
Solo JSON.


MINIMAL (batch ultra‚Äëcompacto)

[system]
Eres experto retail CL. Solo JSON v√°lido.

[user]
P:{name_raw}|C:smartphones|$:${price_clp}
Out:{"brand","model","normalized_name","attributes":{"capacity","color","screen_size","network"},"confidence","category_suggestion"}


FALLBACK (fallback_model, m√°s tokens, temperatura 0.05)

[system]
Experto retail CL. Responde SOLO JSON v√°lido.

[user]
Corrige y completa normalizaci√≥n (JSON). Si datos faltantes, infiere con cautela.
PRODUCTO: "{name_raw}"
CATEGOR√çA_REFERENCIA: "smartphones"
PRECIO_CLP: {price_clp}
RETAILER: "{retailer}"

Estructura EXACTA y tipos correctos:
{ ... (misma estructura que STANDARD) ... }

B) Notebooks

STANDARD

[system] (igual)

[user]
Normaliza:

PRODUCTO: "{name_raw}"
CATEGOR√çA: "notebooks"
PRECIO_CLP: {price_clp}
RETAILER: "{retailer}"

JSON EXACTO:
{
  "brand": "MAY√öSCULAS",
  "model": "modelo sin marca",
  "normalized_name": "BRAND MODEL + specs clave",
  "attributes": {
    "screen_size": "ej: 16",
    "ram": "ej: 16GB",
    "storage": "ej: 512GB SSD"
  },
  "confidence": 0.0,
  "category_suggestion": "notebooks|notebooks_premium|vac√≠o"
}
Solo JSON.


MINIMAL (batch)

[system] (igual)
[user]
P:{name_raw}|C:notebooks|$:${price_clp}
Out:{"brand","model","normalized_name","attributes":{"screen_size","ram","storage"},"confidence","category_suggestion"}

C) Smart TV

STANDARD

[system] (igual)
[user]
Normaliza:

PRODUCTO: "{name_raw}"
CATEGOR√çA: "smart_tv"
PRECIO_CLP: {price_clp}
RETAILER: "{retailer}"

JSON EXACTO:
{
  "brand": "MAY√öSCULAS",
  "model": "modelo sin marca",
  "normalized_name": "BRAND MODEL tama√±o + panel",
  "attributes": {
    "screen_size": "ej: 55",
    "panel": "OLED|QLED|4K|8K|FHD|HD"
  },
  "confidence": 0.0,
  "category_suggestion": "smart_tv|vac√≠o"
}
Solo JSON.

D) Perfumes

STANDARD

[system] (igual)
[user]
Normaliza:

PRODUCTO: "{name_raw}"
CATEGOR√çA: "perfumes"
PRECIO_CLP: {price_clp}
RETAILER: "{retailer}"

JSON EXACTO:
{
  "brand": "MAY√öSCULAS",
  "model": "l√≠nea/fragancia sin marca",
  "normalized_name": "BRAND FRAGANCIA volumen + tipo",
  "attributes": {
    "volume_ml": 0,
    "concentration": "EDP|EDT|Parfum",
    "gender": "Mujer|Hombre|Unisex"
  },
  "confidence": 0.0,
  "category_suggestion": "perfumes|vac√≠o"
}
Solo JSON.

üì¶ Batch API ‚Äî Construcci√≥n y Env√≠o

Archivo JSONL (por modelo):

{"custom_id":"b20250910_00001_FAL-SKU123","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4o-mini","messages":[{"role":"system","content":"Eres experto retail CL. Solo JSON v√°lido."},{"role":"user","content":"P:iPhone 15 Pro Max 256GB Negro|C:smartphones|$:1299990\nOut:{\"brand\",\"model\",\"normalized_name\",\"attributes\":{\"capacity\",\"color\",\"screen_size\",\"network\"},\"confidence\",\"category_suggestion\"}"}],"temperature":0.1,"max_tokens":300,"response_format":{"type":"json_object"}}}


Ciclo de vida: upload ‚Üí create batch (24h) ‚Üí poll ‚Üí download *_results.jsonl ‚Üí reconcilia por custom_id.
Costo: Batch ‚Äë50% vs individual (seg√∫n v1).

üß† Cache Inteligente (L1/L2/L3)

L1 (Redis hot): clave {ns}:{fingerprint} ‚Üí JSON IA; TTL por categor√≠a; hit <200ms.

L2 (Sem√°ntico): embeddings (OpenAI text-embedding-3-small u otro) en pgvector (o Milvus). √çndice HNSW/IVFFlat.

Umbral por categor√≠a (similarity_threshold.*); si sim ‚â• Œ∏, reutiliza y adapta diferencias simples (capacidad, color).

L3 (PostgreSQL): ai_metadata_cache (persistente) con custom_id/fingerprint, model_used, prompt_version, ai_confidence, metadata (JSONB).

Invalidaci√≥n: version_namespace en clave; bump al cambiar prompts/modelos/esquemas.

üß± Persistencia (idempotente)

Orden

ai_metadata_cache UPSERT (por fingerprint o custom_id).

Vector DB UPSERT (embedding de name_raw/normalized_name).

productos_maestros UPSERT (fingerprint √∫nico), campos: brand, model, normalized_name, category, attributes, ai_enhanced=true, ai_confidence, processing_version="v2".

precios_actuales UPSERT por product_id con price_current, currency="CLP".

√çndices recomendados

pgvector: CREATE INDEX idx_vec_name ON ai_embeddings USING hnsw(embedding vector_cosine_ops) WITH (m=16, ef_construction=64);

JSONB: GIN sobre ai_metadata_cache(metadata) para queries anal√≠ticas.

üßØ Throttling, Retries y Resiliencia

Rate limits: token‚Äëbucket por modelo (rpm_primary, rpm_fallback).

Circuit breakers: si %429/%5xx supera umbral (p.ej., 3% en 5 min), pausar env√≠os y degradar a cache/individual.

Retries: exponencial con jitter (p.ej., 1s, 2s, 4s, m√°x 3 intentos por √≠tem).

Plan B: si batch falla/timeout, reintentar individuales con primary; si gating falla, fallback.

üìä Observabilidad

M√©tricas clave

%cache_hit_l1, %cache_hit_l2, %llm_invocations, %fallback_full

avg_confidence, attr_coverage, precision_sampled

tokens_in/out, cost_usd_total, cost_per_product

latency_cache_hit, latency_llm, latency_batch_end2end

Alertas

Budget diario (p.ej., $50)

Fallback rate > umbral (p.ej., 12%)

Confidence avg < 0.8 por categor√≠a

A/B de prompts

Bandera prompt_version en system y en cache; comparar costo/precisi√≥n por versi√≥n.

v1 ya detallaba KPIs de batch y ahorro; v2 incorpora gating/validaci√≥n m√©tricas.

‚úÖ Checklists de Producci√≥n

 OPENAI_API_KEY y modelos en config (primary_model, fallback_model)

 Redis operativo + TTL por categor√≠a

 pgvector (o Milvus) con √≠ndices y umbrales configurados

 Taxonom√≠a cargada y attribute schema por categor√≠a (whitelist + tipos)

 Gating (umbrales) y fallback activados

 Idempotencia por custom_id y fingerprint en BD y cache

 Dashboards de m√©tricas/costos/errores

 Prueba piloto (1.000 √≠tems) y rollback plan

 Versionado de prompts (prompt_version) y namespace de cache

üóÇÔ∏è Qu√© debes sustituir / agregar (paso a paso)

Reemplazar BATCH_PROCESSING_FLOW.md por este v2. (Este archivo)

Configurar config.llm.toml (bloques llm, validation, vector, cache, rate_limits).

Prompts

Crear prompts/ con sub‚Äëcarpetas por categor√≠a y archivos: standard.md, minimal.md, fallback.md (usar textos exactos arriba).

A√±adir prompt_version para trazabilidad.

Cache

Desplegar Redis (L1), definir TTLs por categor√≠a.

Montar pgvector/Milvus (L2); crear √≠ndice; implementar upsert embedding.

Validador

A√±adir m√≥dulo validator/ con:

taxonomy_validator.py (check ID/sin√≥nimo)

attributes_schema.py (whitelist/tipado por categor√≠a)

brand_aliases.py (mapping)

gating.py (confidence + coverage)

Persistencia

Asegurar UPSERTs (ai_metadata_cache, productos_maestros, precios_actuales) con custom_id/fingerprint.

Throttling/Resiliencia

Implementar token‚Äëbucket y circuit breakers en el submitter (batch/individual).

M√©tricas

Exponer contadores (%cache_hit_l1/l2, %fallback_full, costs, latencies).

üìö Ap√©ndice A ‚Äî JSON Schema (salida IA)

√ösalo para validar respuestas antes de BD (ej. jsonschema).

{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "IA Normalized Product v2",
  "type": "object",
  "required": ["brand","model","normalized_name","attributes","confidence"],
  "properties": {
    "brand": { "type": "string", "minLength": 1 },
    "model": { "type": "string", "minLength": 1 },
    "normalized_name": { "type": "string", "minLength": 5 },
    "attributes": { "type": "object", "additionalProperties": true },
    "confidence": { "type": "number", "minimum": 0, "maximum": 1 },
    "category_suggestion": { "type": "string" }
  },
  "additionalProperties": false
}

üìö Ap√©ndice B ‚Äî SQL (pgvector & JSONB)
-- Extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Tabla de embeddings (si separada)
CREATE TABLE IF NOT EXISTS ai_embeddings (
  fingerprint TEXT PRIMARY KEY,
  embedding vector(1536),
  created_at TIMESTAMPTZ DEFAULT now()
);

-- √çndice HNSW
CREATE INDEX IF NOT EXISTS idx_ai_embeddings_hnsw
ON ai_embeddings USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- GIN sobre metadata JSONB (consultas anal√≠ticas)
CREATE INDEX IF NOT EXISTS idx_ai_cache_metadata_gin
ON ai_metadata_cache USING GIN ((metadata));

üìö Ap√©ndice C ‚Äî Redis keys & TTL

Key: {version_namespace}:{fingerprint}

Value: JSON IA completo (brand, model, normalized_name, attributes, confidence, category_suggestion, model_used, prompt_version).

TTL: por categor√≠a (config) + ajuste si detectas mayor volatilidad (e.g., TVs en campa√±as ‚Üí TTL m√°s corto).

üß≠ Notas de alineaci√≥n con v1

Se mantiene Batch API + JSONL con custom_id para idempotency mapping y descarga de resultados (tu v1 ya lo detalla).
