#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
游꿢 Prompts Espec칤ficos Optimizados para GPT-5
Prompts por modelo, categor칤a y modo de procesamiento
"""

from enum import Enum
from typing import Dict, Any

class PromptMode(Enum):
    """Modos de prompt seg칰n contexto"""
    MINIMAL = "minimal"      # 30 tokens - Ultra compacto para batch
    BATCH = "batch"          # 40 tokens - Optimizado batch
    STANDARD = "standard"    # 100 tokens - Balance calidad/costo
    DETAILED = "detailed"    # 200 tokens - M치xima precisi칩n
    FALLBACK = "fallback"    # Variable - Correcci칩n con contexto

class PromptManager:
    """Gestor de prompts optimizados por modelo y categor칤a"""
    
    def __init__(self):
        self.version = "v2.0"
        self._init_prompts()
        self._init_system_prompts()
    
    def _init_system_prompts(self):
        """System prompts por modelo"""
        self.system_prompts = {
            "gpt-5-mini": "Eres un experto en normalizaci칩n de productos retail chilenos. Responde SOLO en formato JSON v치lido sin texto adicional.",
            "gpt-5": "Eres un especialista en an치lisis de productos retail con conocimiento profundo del mercado chileno. Genera JSON estructurado y preciso.",
            "gpt-4o-mini": "Experto retail Chile. Solo JSON v치lido RFC 8259.",
            "gpt-4o": "Analista experto de productos retail chilenos. Respuesta exclusivamente en JSON v치lido con alta precisi칩n."
        }
    
    def _init_prompts(self):
        """Definir todos los prompts espec칤ficos"""
        self.prompts = {
            "gpt-5-mini": {
                "smartphones": {
                    PromptMode.MINIMAL: self._minimal_smartphone,
                    PromptMode.BATCH: self._batch_smartphone,
                    PromptMode.STANDARD: self._standard_smartphone
                },
                "notebooks": {
                    PromptMode.MINIMAL: self._minimal_notebook,
                    PromptMode.BATCH: self._batch_notebook,
                    PromptMode.STANDARD: self._standard_notebook
                },
                "smart_tv": {
                    PromptMode.MINIMAL: self._minimal_tv,
                    PromptMode.BATCH: self._batch_tv,
                    PromptMode.STANDARD: self._standard_tv
                },
                "perfumes": {
                    PromptMode.MINIMAL: self._minimal_perfume,
                    PromptMode.BATCH: self._batch_perfume,
                    PromptMode.STANDARD: self._standard_perfume
                },
                "default": {
                    PromptMode.MINIMAL: self._minimal_default,
                    PromptMode.BATCH: self._batch_default,
                    PromptMode.STANDARD: self._standard_default
                }
            },
            "gpt-5": {
                "smartphones": {PromptMode.DETAILED: self._detailed_smartphone},
                "notebooks": {PromptMode.DETAILED: self._detailed_notebook},
                "smart_tv": {PromptMode.DETAILED: self._detailed_tv},
                "perfumes": {PromptMode.DETAILED: self._detailed_perfume},
                "default": {PromptMode.DETAILED: self._detailed_default}
            },
            "gpt-4o-mini": {
                "all": {PromptMode.FALLBACK: self._fallback_prompt}
            },
            "gpt-4o": {
                "all": {PromptMode.FALLBACK: self._fallback_detailed}
            }
        }
    
    def get_prompt(self, model: str, category: str, mode: PromptMode, 
                   product: Dict[str, Any], **kwargs) -> str:
        """Obtener prompt apropiado"""
        
        # Buscar prompt espec칤fico
        model_prompts = self.prompts.get(model, {})
        
        # Intentar categor칤a espec칤fica
        category_prompts = model_prompts.get(category, {})
        if not category_prompts:
            # Fallback a default o all
            category_prompts = model_prompts.get("default", model_prompts.get("all", {}))
        
        # Obtener funci칩n de prompt
        prompt_func = category_prompts.get(mode)
        
        if prompt_func:
            return prompt_func(product, **kwargs)
        
        # Fallback a standard
        return self._standard_default(product)
    
    # ============================================================================
    # SMARTPHONES - Prompts
    # ============================================================================
    
    def _minimal_smartphone(self, product: Dict, **kwargs) -> str:
        """Ultra compacto para batch masivo"""
        return f"N:{product.get('name', '')[:80]}|C:smartphones|$:{product.get('price', 0)}"
    
    def _batch_smartphone(self, product: Dict, **kwargs) -> str:
        """Optimizado para batch"""
        return f"""Smartphone:{product.get('name', '')[:100]}[${product.get('price', 0)}]
JSON:brand,model,capacity,color,screen_size,network"""
    
    def _standard_smartphone(self, product: Dict, **kwargs) -> str:
        """Balance calidad/costo"""
        return f"""Normaliza el siguiente smartphone:

PRODUCTO: "{product.get('name', '')}"
PRECIO: ${product.get('price', 0):,} CLP
RETAILER: "{product.get('retailer', '')}"

Extrae y estructura en JSON:
{{
  "brand": "MARCA_MAYUSCULAS",
  "model": "modelo sin marca",
  "normalized_name": "MARCA Modelo Capacidad Color",
  "attributes": {{
    "capacity": "128GB/256GB/512GB/1TB",
    "color": "color en espa침ol",
    "screen_size": "pulgadas como n칰mero",
    "network": "4G/5G"
  }},
  "confidence": 0.00,
  "category_suggestion": "smartphones"
}}"""
    
    def _detailed_smartphone(self, product: Dict, **kwargs) -> str:
        """An치lisis exhaustivo con GPT-5"""
        return f"""Analiza exhaustivamente este smartphone del mercado chileno:

DATOS DE ENTRADA:
- Nombre completo: "{product.get('name', '')}"
- Precio CLP: ${product.get('price', 0):,}
- Retailer: {product.get('retailer', '')}
- SKU/ID: {product.get('sku', 'N/A')}

INSTRUCCIONES DE EXTRACCI칍N:
1. Identificar marca exacta (verificar aliases y variaciones)
2. Extraer modelo completo con variante si existe
3. Detectar TODOS los atributos t칠cnicos presentes
4. Normalizar nombre para matching inter-retail
5. Evaluar confianza basada en completitud de datos

ESTRUCTURA JSON REQUERIDA:
{{
  "brand": "MARCA_OFICIAL_MAYUSCULAS",
  "model": "modelo completo con variante",
  "normalized_name": "MARCA Modelo Capacidad Color (atributos clave)",
  "attributes": {{
    "capacity": "almacenamiento exacto",
    "color": "color normalizado",
    "screen_size": "tama침o en pulgadas",
    "network": "tecnolog칤a de red",
    "processor": "procesador si se menciona",
    "ram": "RAM si se menciona",
    "camera": "MP c치mara principal si se menciona"
  }},
  "confidence": 0.00,
  "category_suggestion": "smartphones",
  "extraction_notes": "notas sobre ambig칲edades o inferencias"
}}"""
    
    # ============================================================================
    # NOTEBOOKS - Prompts
    # ============================================================================
    
    def _minimal_notebook(self, product: Dict, **kwargs) -> str:
        return f"N:{product.get('name', '')[:80]}|C:notebooks|$:{product.get('price', 0)}"
    
    def _batch_notebook(self, product: Dict, **kwargs) -> str:
        return f"""Notebook:{product.get('name', '')[:100]}[${product.get('price', 0)}]
JSON:brand,model,screen_size,ram,storage,processor"""
    
    def _standard_notebook(self, product: Dict, **kwargs) -> str:
        return f"""Normaliza el siguiente notebook:

PRODUCTO: "{product.get('name', '')}"
PRECIO: ${product.get('price', 0):,} CLP

Estructura JSON:
{{
  "brand": "MARCA_MAYUSCULAS",
  "model": "modelo sin marca",
  "normalized_name": "MARCA Modelo RAM Storage",
  "attributes": {{
    "screen_size": "pulgadas",
    "ram": "GB RAM",
    "storage": "capacidad y tipo",
    "processor": "procesador si se menciona"
  }},
  "confidence": 0.00,
  "category_suggestion": "notebooks"
}}"""
    
    def _detailed_notebook(self, product: Dict, **kwargs) -> str:
        return f"""An치lisis detallado de notebook:

ENTRADA: "{product.get('name', '')}"
PRECIO: ${product.get('price', 0):,} CLP

Extraer TODO incluyendo:
- Marca y l칤nea de producto
- Procesador espec칤fico (generaci칩n)
- RAM (capacidad y tipo)
- Almacenamiento (SSD/HDD, capacidad)
- Pantalla (tama침o, resoluci칩n si existe)
- GPU si se menciona
- Sistema operativo

JSON con todos los atributos detectados."""
    
    # ============================================================================
    # SMART TV - Prompts
    # ============================================================================
    
    def _minimal_tv(self, product: Dict, **kwargs) -> str:
        return f"N:{product.get('name', '')[:80]}|C:smart_tv|$:{product.get('price', 0)}"
    
    def _batch_tv(self, product: Dict, **kwargs) -> str:
        return f"""TV:{product.get('name', '')[:100]}[${product.get('price', 0)}]
JSON:brand,model,screen_size,panel,resolution"""
    
    def _standard_tv(self, product: Dict, **kwargs) -> str:
        return f"""Normaliza Smart TV:

"{product.get('name', '')}"
${product.get('price', 0):,} CLP

JSON:
{{
  "brand": "MARCA",
  "model": "modelo",
  "normalized_name": "MARCA Modelo Pulgadas Panel",
  "attributes": {{
    "screen_size": "pulgadas",
    "panel": "OLED/QLED/LED/4K/8K",
    "resolution": "4K/8K/FHD/HD"
  }},
  "confidence": 0.00,
  "category_suggestion": "smart_tv"
}}"""
    
    def _detailed_tv(self, product: Dict, **kwargs) -> str:
        return f"""Smart TV an치lisis completo:
{product.get('name', '')}

Extraer marca, l칤nea, tecnolog칤a de panel, resoluci칩n, 
smart features, HDR, audio, a침o si existe."""
    
    # ============================================================================
    # PERFUMES - Prompts
    # ============================================================================
    
    def _minimal_perfume(self, product: Dict, **kwargs) -> str:
        return f"N:{product.get('name', '')[:80]}|C:perfumes|$:{product.get('price', 0)}"
    
    def _batch_perfume(self, product: Dict, **kwargs) -> str:
        return f"""Perfume:{product.get('name', '')[:100]}[${product.get('price', 0)}]
JSON:brand,model,volume_ml,concentration,gender"""
    
    def _standard_perfume(self, product: Dict, **kwargs) -> str:
        return f"""Normaliza perfume:

"{product.get('name', '')}"
${product.get('price', 0):,} CLP

JSON:
{{
  "brand": "MARCA",
  "model": "fragancia",
  "normalized_name": "MARCA Fragancia Volume Tipo",
  "attributes": {{
    "volume_ml": numero_entero,
    "concentration": "EDP/EDT/Parfum/Cologne",
    "gender": "Mujer/Hombre/Unisex"
  }},
  "confidence": 0.00,
  "category_suggestion": "perfumes"
}}"""
    
    def _detailed_perfume(self, product: Dict, **kwargs) -> str:
        return f"""Perfume an치lisis:
{product.get('name', '')}

Identificar marca exacta, l칤nea de fragancia, 
volumen en ml, concentraci칩n (EDP/EDT/Parfum),
g칠nero target, notas si se mencionan."""
    
    # ============================================================================
    # DEFAULT - Prompts gen칠ricos
    # ============================================================================
    
    def _minimal_default(self, product: Dict, **kwargs) -> str:
        return f"N:{product.get('name', '')[:100]}|C:{product.get('category', '')}|$:{product.get('price', 0)}"
    
    def _batch_default(self, product: Dict, **kwargs) -> str:
        return f"""Producto:{product.get('name', '')[:120]}[{product.get('category', '')}]
Precio:${product.get('price', 0)}
JSON:brand,model,normalized_name,attributes,confidence"""
    
    def _standard_default(self, product: Dict, **kwargs) -> str:
        return f"""Normaliza producto:

NOMBRE: "{product.get('name', '')}"
CATEGOR칈A: "{product.get('category', '')}"
PRECIO: ${product.get('price', 0):,} CLP

Estructura JSON con:
- brand (marca en may칰sculas)
- model (modelo sin marca)
- normalized_name (nombre limpio)
- attributes (objeto con atributos relevantes)
- confidence (0.0 a 1.0)
- category_suggestion (si difiere)"""
    
    def _detailed_default(self, product: Dict, **kwargs) -> str:
        return f"""An치lisis exhaustivo:

PRODUCTO COMPLETO: {product.get('name', '')}
CATEGOR칈A BASE: {product.get('category', '')}
PRECIO: ${product.get('price', 0):,} CLP
RETAILER: {product.get('retailer', '')}

Extraer TODOS los atributos detectables.
Normalizar para comparaci칩n inter-retail.
Evaluar confianza de extracci칩n."""
    
    # ============================================================================
    # FALLBACK - Prompts de correcci칩n
    # ============================================================================
    
    def _fallback_prompt(self, product: Dict, **kwargs) -> str:
        """Fallback b치sico para correcci칩n"""
        previous = kwargs.get('previous_attempt', {})
        error = kwargs.get('error', 'JSON inv치lido o incompleto')
        
        return f"""Corrige el siguiente resultado:

PRODUCTO ORIGINAL: "{product.get('name', '')}"
CATEGOR칈A: "{product.get('category', '')}"

INTENTO ANTERIOR:
{previous}

ERROR: {error}

Genera JSON v치lido corregido con todos los campos requeridos:
brand, model, normalized_name, attributes, confidence, category_suggestion"""
    
    def _fallback_detailed(self, product: Dict, **kwargs) -> str:
        """Fallback detallado con GPT-4o"""
        previous = kwargs.get('previous_attempt', {})
        error = kwargs.get('error', '')
        
        return f"""An치lisis y correcci칩n experta:

CONTEXTO:
- Producto: "{product.get('name', '')}"
- Categor칤a: "{product.get('category', '')}"
- Precio: ${product.get('price', 0):,} CLP
- Retailer: {product.get('retailer', '')}

PROBLEMA DETECTADO:
{error}

INTENTO PREVIO:
{previous}

INSTRUCCIONES:
1. Identificar qu칠 falt칩 o fall칩 en el intento anterior
2. Completar TODOS los campos requeridos
3. Inferir datos faltantes con alta precisi칩n
4. Asegurar JSON v치lido y completo

ESTRUCTURA REQUERIDA:
{{
  "brand": "obligatorio",
  "model": "obligatorio", 
  "normalized_name": "obligatorio",
  "attributes": {{}},
  "confidence": 0.0,
  "category_suggestion": "opcional"
}}"""
    
    def get_tokens_estimate(self, mode: PromptMode) -> int:
        """Estimar tokens por modo"""
        estimates = {
            PromptMode.MINIMAL: 30,
            PromptMode.BATCH: 40,
            PromptMode.STANDARD: 100,
            PromptMode.DETAILED: 200,
            PromptMode.FALLBACK: 150
        }
        return estimates.get(mode, 100)

# ============================================================================
# Singleton para uso global
# ============================================================================

_prompt_manager = None

def get_prompt_manager() -> PromptManager:
    """Obtener instancia singleton del gestor de prompts"""
    global _prompt_manager
    if _prompt_manager is None:
        _prompt_manager = PromptManager()
    return _prompt_manager

if __name__ == "__main__":
    # Testing
    pm = get_prompt_manager()
    
    test_product = {
        "name": "iPhone 15 Pro Max 256GB Negro Liberado",
        "category": "smartphones",
        "price": 1299990,
        "retailer": "Falabella"
    }
    
    # Test diferentes modos
    for mode in [PromptMode.MINIMAL, PromptMode.BATCH, PromptMode.STANDARD]:
        prompt = pm.get_prompt("gpt-5-mini", "smartphones", mode, test_product)
        tokens = pm.get_tokens_estimate(mode)
        print(f"\n=== {mode.value.upper()} ({tokens} tokens) ===")
        print(prompt[:200] + "..." if len(prompt) > 200 else prompt)